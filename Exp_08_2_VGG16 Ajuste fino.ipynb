{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "Exp_08_2_Lab_Introdução_ao_Processamento_Digital_de_Imagens_e_Visão_Computacional (1).ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmnfW_fK8Q0g"
      },
      "source": [
        "<img src=\"https://www.anped.org.br/sites/default/files/images/ufcg-lateral.png\" width=\"780\" height=\"240\" align=\"center\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSO4vGEx8Q0i"
      },
      "source": [
        "## Centro de Engenharia Elétrica e Informática\n",
        "## Departamento de Engenharia Elétrica\n",
        "## Disciplina: Int. ao Processamento de Imagem Digital e Visão Computacional\n",
        "## Professora: Luciana Veloso\n",
        "## Aluno(a):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGf_8YBQ8Q0j"
      },
      "source": [
        "# Experimento 08: Ajuste Fino"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nhBypGY8Q0k"
      },
      "source": [
        "import os                                             # Operational System para manipulação de arquivos.\n",
        "import cv2                                            # OpenCV para manipulação de imagens.\n",
        "import random\n",
        "import numpy as np                                    # Numpy para manipulação de matrizes e arrays.\n",
        "import matplotlib.pyplot as plt                       # Pyplot para plotagem de gráficos e imagens.\n",
        "from sklearn.metrics import confusion_matrix          # Scikit-Learn para plotar a matriz de confusão\n",
        "\n",
        "from tensorflow.keras import layers                   # Módulo de camadas do Keras\n",
        "from tensorflow.keras import callbacks                # Módulo de callbacks do Keras\n",
        "from tensorflow.keras import optimizers               # Módulo de otimizadores do Keras\n",
        "from tensorflow.keras.models import load_model        # Função para carregar um modelo salvo\n",
        "from tensorflow.keras.applications import VGG16       # Classe de modelos sequenciais para construir as redes neurais.\n",
        "\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "# ImageDataGenerator, utilizado para carregar imagens em tempo de execução\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOBGpuiE8Q0l"
      },
      "source": [
        "## 1. Dados do Experimento\n",
        "\n",
        "* Vamos utilizar o banco de dados Cats vs Dogs, que foi utilizado no Desafio Prático;\n",
        "\n",
        "* Cada instância do banco de dados corresponde a uma imagem rotulada de um Cachorro ou um Gato;\n",
        "\n",
        "* As imagens do banco de dados são coloridas e foram redimensionadas para 150x150;\n",
        "\n",
        "* Imagens de Cachorro têm rótulo 0 e as de Gato têm rótulo 1;\n",
        "\n",
        "* A versão que estamos usando tem 3000 imagens, 2000 para treino, 500 para validação e 500 para teste;\n",
        "\n",
        "* Todas as partições da base de dados são balanceadas;\n",
        "\n",
        "* Os dados do experimento podem ser baixados no [link](https://drive.google.com/file/d/1iYleZOPahuxO-u0TGNPiuxvKZt0tQgqe/view?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlg2jverAldN",
        "outputId": "1bee772e-8c2d-4d5b-ff5b-231a58d35bb6"
      },
      "source": [
        "gdd.download_file_from_google_drive(file_id = '1iYleZOPahuxO-u0TGNPiuxvKZt0tQgqe',\n",
        "                                    dest_path = './dados_exp_8.zip',\n",
        "                                    unzip = True)\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id = '16OmmOh8abTNv3xxFVpH3s77D90uO041g',\n",
        "                                    dest_path = './model.h5',\n",
        "                                    unzip = False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1iYleZOPahuxO-u0TGNPiuxvKZt0tQgqe into ./dados_exp_8.zip... Done.\n",
            "Unzipping...Done.\n",
            "Downloading 16OmmOh8abTNv3xxFVpH3s77D90uO041g into ./model.h5... Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weT1NL8B8Q0m"
      },
      "source": [
        "### 1.1. Carregando dados em tempo Real\n",
        "\n",
        "O Keras disponibiliza um objeto ImageDataGenerator para o carregamento de dados em tempo real durante o treinamento de modelos. São necessárias duas etapas para configurar o objeto:\n",
        "\n",
        "1. Definição das transformações realizadas sobre os dados, ao instanciar o ImageDataGenerator propriamente dito:\n",
        "    * Isso pode ser feito a partir de **datagen = ImageDataGenerator( rescale = 1./255 )**\n",
        "    * Nesse exemplo o único parâmetro setado é o rescale, que define uma constante para normalizar as imagens carregadas.\n",
        "    * Outras transformações podem ser especificadas utilizando outros parâmetros;\n",
        "2. Definição do método de carregamento:\n",
        "    * Os dados podem ser carregados com base em uma estrutura de diretórios ou a partir de um dataframe;\n",
        "    * Vamos utilizar o método **flow_from_directory** para carregar os dados com base na estrutura de dados montada;\n",
        "    * A chamada do método se faz a partir de **generator = datagen.flow_from_directory( data_dir, target_size, batch_size, class_mode)**\n",
        "        * generator é um objeto de fornece exemplos continuamente a não ser que seja explicitamente encerrado ( while(True) );\n",
        "        * data_dir é o diretório raiz dos dados, dentro dessa pasta os exemplos devem estar divididos por classe em pastas distintas;\n",
        "        * target_size é uma tupla que especifica o tamanho das imagens carregadas;\n",
        "        * class_mode define como os gabaritos são carregados, se **\"binary\"** carrega os gabaritos como inteiros 0 ou 1, se **\"categorical\"** carrega gabaritos categóricas conforme usadas no Exp. 7, se **None** não carrega gabaritos;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTpLHo-T8Q0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240002a5-01d6-40cb-fcf7-72677c3cca76"
      },
      "source": [
        "val_datagen   = ImageDataGenerator( rescale = 1./255 )\n",
        "val_generator = val_datagen.flow_from_directory( os.path.join(\".\", \"data\", \"val\"), target_size = (150, 150),\n",
        "                                                 batch_size  = 20, class_mode  = \"binary\")\n",
        "\n",
        "# Atributo do generator que fornece o número de amostras detectadas\n",
        "val_samples = val_generator.samples \n",
        "print(val_samples, \"amostras detectadas\")\n",
        "\n",
        "# Atributo do generator que fornece o mapeamento de classe para índice \n",
        "# Repare que os índices são definidos pelo generator com base nos diretórios de arquivos em ordem alfabética\n",
        "class_to_idx_dict = val_generator.class_indices\n",
        "print( \"Mapeamento Classes -> Índices:\", class_to_idx_dict )\n",
        "\n",
        "# Construção de um novo dicionário que inverte o mapeamento\n",
        "idx_to_class_dict = { v: k for k, v in class_to_idx_dict.items() }\n",
        "print( \"Mapeamento Índices -> Classes:\", idx_to_class_dict )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n",
            "1000 amostras detectadas\n",
            "Mapeamento Classes -> Índices: {'Cachorro': 0, 'Gato': 1}\n",
            "Mapeamento Índices -> Classes: {0: 'Cachorro', 1: 'Gato'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kp9MpqT8Q0p"
      },
      "source": [
        "### 1.2. Aumento de Dados\n",
        "\n",
        "Outras transformações possíveis no ImageDataGenerator viabilizam o aumento de dados. Nesse sentido, é possível definir transformações aleatórias que são realizadas conforme os dados são carregados para simular um banco de dados maior.\n",
        "\n",
        "* Exemplos de transformações aleatórias são:\n",
        "    * rotation_range valor que define o valor máximo (em graus) das rotações aleatórias realizadas;\n",
        "    * width_shift_range valor (em fração) que determina o valor máximo de uma translação horizontal realizada com base na largura da imagem;\n",
        "    * height_shift_range valor (em fração) que determina o valor máximo de uma translação vertical realizada com base na altura da imagem;\n",
        "    * zoom_range valor (em fração) que determina o maior zoom aleatório realizado na imagem;\n",
        "    * shear_range valor (em fração) que determina a maior deformação aleatória realizada na imagem;\n",
        "    * horizontal_flip booleano que determina se reflexões horizontais devem ser aplicadas aleatoriamente na imagem;\n",
        "    * vertical_flip booleano que determina se reflexões verticais devem ser aplicadas aleatoriamente na imagem;\n",
        "    * fill_mode modo de preenchimento de buracos provocados pelas transformações realizadas:\n",
        "        * 'constant': preenche os buracos com um valor constante que pode ser fornecido pelo parâmetro **cval**;\n",
        "        * 'nearest': preenche os buracos com a repetição dos elementos mais próximos das suas bordas;\n",
        "        * 'reflect': preenche os buracos com a reflexão dos elementos mais próximos das suas bordas;\n",
        "        * 'wrap': preenche os buracos considerando a imagem como um sinal periódico;\n",
        "        \n",
        "* Mais informações em https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z0NE5YV8Q0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6139ad-9e27-479c-90a2-a29de9139110"
      },
      "source": [
        "train_datagen = ImageDataGenerator( rescale = 1./255,           #\n",
        "                                    rotation_range = 45,        # Rotação aleatória de até 40°\n",
        "                                    width_shift_range = 0.2,    # Translação horizontal de até 20% da largura\n",
        "                                    height_shift_range = 0.2,   # Translação vertical de até 20% da altura\n",
        "                                    zoom_range = 0.2,           # Zoom aleatório de até 20%\n",
        "                                    shear_range=0.2,            # Deformação de 20%\n",
        "                                    horizontal_flip = True,     # Espelhamento horizontal aleatório\n",
        "                                    vertical_flip = False,      # Espelhamento vertical aleatório\n",
        "                                    fill_mode = \"nearest\")      # Preenchimentod e buracos pelo pixel mais próximo\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory( os.path.join(\".\", \"data\", \"train\"), target_size = (150, 150),\n",
        "                                                     batch_size  = 20, class_mode  = \"binary\")\n",
        "\n",
        "# Atributo do generator que fornece o número de amostras detectadas\n",
        "train_samples = train_generator.samples \n",
        "print(train_samples)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1tXLeId8Q0r"
      },
      "source": [
        "**a. A utilização de aumento de dados substitui ou expande o banco de dados? Justifique.**\n",
        "\n",
        "<font color='gree'>\n",
        "O data generator emula um banco de dados maior com base nas amostras do dataset original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS66pdejmE9Y"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzgW2-lD8Q0s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXKnpNEt8Q0s"
      },
      "source": [
        "## 2. Carregando o Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQHabJYe8Q0t"
      },
      "source": [
        "* Dessa vez vamos carregar o modelo treinado na parte 1 do experimento:\n",
        "    * **model = load_model(path)**\n",
        "    * Esse comando carrega todas as informações do modelo treinado, incluindo arquitetura e os pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsuxbiVt8Q0t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fc35d6-e4d4-4166-bbd2-b912048c7a86"
      },
      "source": [
        "model = load_model(\"model.h5\")\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 2,097,665\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k-HyZ-A8Q0u"
      },
      "source": [
        "### 2.2. Acessando Camadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcnbYkLN8Q0u"
      },
      "source": [
        "* No Keras podemos acessar as camadas do modelo individualmente através do atributo **layers** de um modelo, que retorna uma lista das suas camadas. É possível verificar e alterar alguns dos atribudos das camadas, a exemplo de:\n",
        "\n",
        "    * **layer.input_shape** dimensões do tensor de entrada, \"None\" indica uma dimensão coringa, que aceita qualquer tamanho;\n",
        "    * **layer.output_shape** dimensões do tensor de saída, \"None\" indica uma dimensão coringa, que aceita qualquer tamanho;\n",
        "    * **layer.trainable** variável booleana que indica se os pesos da camada são treináveis ou não;\n",
        "    * **layer.name** nome da camada, pode ser modificado a partir do argumento optativo \"name\" nas funções de todas as camadas;\n",
        "\n",
        "\n",
        "* Mais informações sobre as camadas podem ser vistas em: https://keras.io/api/layers/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCd2c-ut8Q0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10450762-ca29-4577-8434-415f6f6cdca7"
      },
      "source": [
        "for layer in model.layers:\n",
        "    status = \"Treinável\" if layer.trainable else \"Congelada\"\n",
        "    print(\"Camada '{}' - Status: {} - Entrada: {} - Saída: {}\".format( layer.name,\n",
        "                                                                       layer.trainable, \n",
        "                                                                       layer.input_shape, \n",
        "                                                                       layer.output_shape ))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Camada 'vgg16' - Status: True - Entrada: (None, 150, 150, 3) - Saída: (None, 4, 4, 512)\n",
            "Camada 'flatten' - Status: True - Entrada: (None, 4, 4, 512) - Saída: (None, 8192)\n",
            "Camada 'dense' - Status: True - Entrada: (None, 8192) - Saída: (None, 256)\n",
            "Camada 'dense_1' - Status: True - Entrada: (None, 256) - Saída: (None, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uXwm-w-8Q0v"
      },
      "source": [
        "Também é possível acessar camadas através da função **get_layer**, que retorna uma camada a partir de uma referência ao seu nome.\n",
        "\n",
        "* Observe a base convolucional da VGG16 é vista como uma única camada, que do ponto de vista do modelo produzida é uma camada treinável.\n",
        "* Contudo, quando verificamos as suas camadas internas é possível ver que todas as elas estão congeladas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYHxs1oY8Q0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b94441e2-4979-43ae-cbd0-ebb2d65b92d5"
      },
      "source": [
        "conv_base = model.get_layer(\"vgg16\")\n",
        "for layer in conv_base.layers:\n",
        "    status = \"Treinável\" if layer.trainable else \"Congelada\"\n",
        "    print(\"Camada '{}' - Status: {} - Entrada: {} - Saída: {}\".format( layer.name,\n",
        "                                                                       status, \n",
        "                                                                       layer.input_shape, \n",
        "                                                                       layer.output_shape ))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Camada 'input_2' - Status: Treinável - Entrada: [(None, 150, 150, 3)] - Saída: [(None, 150, 150, 3)]\n",
            "Camada 'block1_conv1' - Status: Congelada - Entrada: (None, 150, 150, 3) - Saída: (None, 150, 150, 64)\n",
            "Camada 'block1_conv2' - Status: Congelada - Entrada: (None, 150, 150, 64) - Saída: (None, 150, 150, 64)\n",
            "Camada 'block1_pool' - Status: Congelada - Entrada: (None, 150, 150, 64) - Saída: (None, 75, 75, 64)\n",
            "Camada 'block2_conv1' - Status: Congelada - Entrada: (None, 75, 75, 64) - Saída: (None, 75, 75, 128)\n",
            "Camada 'block2_conv2' - Status: Congelada - Entrada: (None, 75, 75, 128) - Saída: (None, 75, 75, 128)\n",
            "Camada 'block2_pool' - Status: Congelada - Entrada: (None, 75, 75, 128) - Saída: (None, 37, 37, 128)\n",
            "Camada 'block3_conv1' - Status: Congelada - Entrada: (None, 37, 37, 128) - Saída: (None, 37, 37, 256)\n",
            "Camada 'block3_conv2' - Status: Congelada - Entrada: (None, 37, 37, 256) - Saída: (None, 37, 37, 256)\n",
            "Camada 'block3_conv3' - Status: Congelada - Entrada: (None, 37, 37, 256) - Saída: (None, 37, 37, 256)\n",
            "Camada 'block3_pool' - Status: Congelada - Entrada: (None, 37, 37, 256) - Saída: (None, 18, 18, 256)\n",
            "Camada 'block4_conv1' - Status: Congelada - Entrada: (None, 18, 18, 256) - Saída: (None, 18, 18, 512)\n",
            "Camada 'block4_conv2' - Status: Congelada - Entrada: (None, 18, 18, 512) - Saída: (None, 18, 18, 512)\n",
            "Camada 'block4_conv3' - Status: Congelada - Entrada: (None, 18, 18, 512) - Saída: (None, 18, 18, 512)\n",
            "Camada 'block4_pool' - Status: Congelada - Entrada: (None, 18, 18, 512) - Saída: (None, 9, 9, 512)\n",
            "Camada 'block5_conv1' - Status: Congelada - Entrada: (None, 9, 9, 512) - Saída: (None, 9, 9, 512)\n",
            "Camada 'block5_conv2' - Status: Congelada - Entrada: (None, 9, 9, 512) - Saída: (None, 9, 9, 512)\n",
            "Camada 'block5_conv3' - Status: Congelada - Entrada: (None, 9, 9, 512) - Saída: (None, 9, 9, 512)\n",
            "Camada 'block5_pool' - Status: Congelada - Entrada: (None, 9, 9, 512) - Saída: (None, 4, 4, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WutLt2t8Q0w"
      },
      "source": [
        "**a. Quais das camadas acima podem ser consideradas mais especializadas e quais podem ser consideradas mais generalistas? Justifique.**\n",
        "\n",
        "<font color='green'> As camadas mais generalistas são as primeiras, pois elas tratam diretamente com as entradas, que ainda não foram filtradas pela rede. Já as ultimas camadas são mais especialistas pois tanto dependem da saída especifica para o problema e já recebem informações/parâmetros filtrados das camadas intermédiarias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K63gPRg28Q0w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZG6sSoo8Q0w"
      },
      "source": [
        "**b. Com base na resposta acima, quais das camadas acima são mais valiosas para o modelo que treinamos? Justifique.**\n",
        "\n",
        "* Lembre-se que a VGG16 foi pré-treinada em outro banco de dados para a classificação de objetos em até 1000 classes distintas.\n",
        "\n",
        "<font color='green'> A camada de entrada e a camada de sáida, pois a camada de entrada é treinável e a camada de saída é respónsavel por conectar todo o resto com nosso modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmdgYeYjne_Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf0hGuay8Q0x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZZrlrlw8Q0x"
      },
      "source": [
        "### 2.3. Descongelando Camadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkJggBO-8Q0x"
      },
      "source": [
        "No Keras, camadas de uma rede podem ter seus pesos congelados, fazendo com que eles não sejam modificados durante o treinamento. \n",
        "\n",
        "* Para fazer isso, basta selecionar uma camada e modificar seu atributo **trainable** para False.\n",
        "* Em contrapartida, para descongelar uma camada basta alterar o mesmo atributo para True."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKM6-I358Q0y"
      },
      "source": [
        "**c. Analise o código abaixo e comente o que é realizado em cada linha.**\n",
        "\n",
        "* Quantas camadas são descongeladas?\n",
        "* Quais camadas são descongeladas?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3GjPXu18Q0y"
      },
      "source": [
        "model.trainable = True\n",
        "conv_base = model.get_layer(\"vgg16\")\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == \"block5_conv2\":\n",
        "        set_trainable = True\n",
        "    if layer.name == \"block5_conv1\": # só adicionei após a instrução de descongelar mais camadas\n",
        "        set_trainable = True\n",
        "    if layer.name == \"block4_conv3\": # após o modelo ter finalizado o treino com o block5_conv1 eu descongelei mais uma camada\n",
        "        set_trainable = True\n",
        "    layer.trainable = set_trainable\n",
        "    # OBS: os ifs acima não foram simultâneamente colocados no código, apenas após o termino de uma ajuste"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isptNhya8Q0y"
      },
      "source": [
        "**d. O ajuste fino dos modelos funciona melhor com pequenos valores para a taxa de aprendizagem.**\n",
        "\n",
        "* A afirmação acima é verdadeira? Justifique.\n",
        "\n",
        "<font color ='green'>\n",
        "Para um caso geral a afirmação acima é verdadeira, já que valores menores implicam em passos mais pequenos a serem realizados pelo modelo, entretanto implica em um tempo mais elevado de treino para que a rede venha a convergir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u0g6OjJ8Q0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa282738-91b5-45f5-8687-c64b7de3686b"
      },
      "source": [
        "model.compile(optimizer=optimizers.Adam(lr=1e-5), \n",
        "              loss=\"binary_crossentropy\", \n",
        "              metrics=[\"acc\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               2097408   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 16,812,353\n",
            "Trainable params: 6,817,281\n",
            "Non-trainable params: 9,995,072\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTGZr3Py8Q0z"
      },
      "source": [
        "## 3. Treinando o Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YASwJ_Z8Q0z"
      },
      "source": [
        "### 3.1. Callbacks\n",
        "\n",
        "* Dessa vez utilizaremos uma nova callback do Keras, o ReduceLROnPlateau.\n",
        "* Essa função modifica a taxa de aprendizagem utilizada durante o treinamento caso a variável monitorada deixe de melhorar por um número pré-definido de epochs.\n",
        "* reduce_lr_on_plateau = callbacks.ReduceLROnPlateau(monitor, factor, patience, verbose)\n",
        "    * monitor é a variável que deve ser monitorada pelo callback;\n",
        "    * factor é a constante que deve ser multiplicada pela taxa de aprendizagem atual caso um ajuste seja realizado;\n",
        "    * patience é o número de epochs sem melhora que devem ocorrer para que um ajuste na taxa de aprendizagem seja realizado;\n",
        "    * verbose é o modo de texto, 1 indica para que o Keras avise quando um novo modelo for salvo;\n",
        "    \n",
        "    \n",
        "* Lista de callbacks disponíveis: https://keras.io/api/callbacks/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vws7casG8Q0z"
      },
      "source": [
        "model_checkpoint = callbacks.ModelCheckpoint(\"model_ft.h5\", monitor = \"val_acc\", save_best_only = True, verbose = 1)\n",
        "reduce_lr_on_plateau = callbacks.ReduceLROnPlateau(monitor = \"val_acc\", factor = 0.75, patience = 3, verbose = 1)\n",
        "\n",
        "# Repare que ao utilizar mais de 1 callback elas devem ser organizadas em uma lista\n",
        "callback_list = [model_checkpoint, reduce_lr_on_plateau]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVVfwTG78Q00"
      },
      "source": [
        "### 3.2. Ajuste dos Pesos\n",
        "\n",
        "O treinamento é realizado a partir da função **fit**, que recebe dados de treino e de validação além de hiperparâmetros como o número de épocas e o tamanho dos lotes de dados (batchsize). Nesse caso, como estamos utilizando generators, não é preciso fornecer os exemplos e os gabaritos separadamente e nem o batchsize:\n",
        "\n",
        "* **hist = model.fit( x = None, steps_per_epoch = None, epochs = 1, callbacks = [], validation_data = None, validation_steps = None, verbose = \"auto\")**\n",
        "    * x corresponde aos dados de treino, também pode ser um generator;\n",
        "    * steps_per_epoch corresponde ao número de lotes (batches) que devem ser produzidos com o generator de treino por epoch;\n",
        "    * epochs corresponde ao número de épocas de treinamento;\n",
        "    * callbacks corresponde à lista de callbacks utilizada;\n",
        "    * validation_data corresponde aos dados de validação, também pode ser um generator;\n",
        "    * validation_steps corresponde ao número de lotes (batches) que devem ser produzidos com o generator de validação por epoch;\n",
        "    * verbose indica como a função deve reportar os resultados:\n",
        "        * 0: modo silencioso, nenhum retorno em formato de texto;\n",
        "        * 1: retorno a cada época e barra de progresso;\n",
        "        * 2: retorno a cada época sem barra de progresso;\n",
        "    * hist é um dicionário de retorno com os valores de loss e das métricas computadas para treino e validação;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SmtNVCo68Q00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "5429d415-17fe-4069-c508-a78f4e9db7fe"
      },
      "source": [
        "history = model.fit( train_generator, steps_per_epoch = 100,\n",
        "                     epochs = 30, callbacks = callback_list, \n",
        "                     validation_data = val_generator, validation_steps = 50 )\n",
        "\n",
        "model.load_weights(\"model_ft.h5\")\n",
        "\n",
        "history_dict = history.history"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            " 22/100 [=====>........................] - ETA: 6:23 - loss: 0.3468 - acc: 0.8545"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7104a489f036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit( train_generator, steps_per_epoch = 100,\n\u001b[1;32m      2\u001b[0m                      \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                      validation_data = val_generator, validation_steps = 50 )\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_ft.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql--jlk_8Q01"
      },
      "source": [
        "### 3.3. Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaEdLZm38Q01"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, squeeze = False, figsize = (16,8))\n",
        "\n",
        "# Loss\n",
        "train_loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "\n",
        "# Epochs\n",
        "epochs = range(1, len(train_loss_values) + 1)\n",
        "\n",
        "# Accuracy\n",
        "train_acc_values = history_dict[\"acc\"]\n",
        "val_acc_values = history_dict[\"val_acc\"]\n",
        "\n",
        "ax = axes.flat[0]\n",
        "ax.plot(epochs, train_loss_values, \"r\", label=\"Training loss\")\n",
        "ax.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "ax.set_title(\"Training and validation Loss\")\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Loss\")\n",
        "ax.legend()\n",
        "\n",
        "ax = axes.flat[1]\n",
        "ax.plot(epochs, train_acc_values, \"r\", label=\"Training acc\")\n",
        "ax.plot(epochs, val_acc_values, \"b\", label=\"Validation acc\")\n",
        "ax.set_title(\"Training and validation Accuracy\")\n",
        "ax.set_xlabel(\"Epochs\")\n",
        "ax.set_ylabel(\"Accuracy\")\n",
        "ax.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OBxaep88Q02"
      },
      "source": [
        "## 4. Teste do Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II4j9_Pd8Q02"
      },
      "source": [
        "### 4.1. Métricas\n",
        "\n",
        "O teste do modelo pode ser realizado a partir da função **evaluate**, que também suporta generators.\n",
        "\n",
        "* Observe que dessa vez utilizou-se o parâmetro \"shuffle\" no flow_from_directory. Isso foi feito para que os exemplos de teste não fossem embaralhados pelo generator e pudessem ser identificados posteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbkfA2xn8Q02"
      },
      "source": [
        "test_datagen   = ImageDataGenerator( rescale = 1./255 )\n",
        "test_generator = test_datagen.flow_from_directory( os.path.join(\".\", \"data\", \"test\"), target_size = (150, 150),\n",
        "                                                   batch_size  = 1, class_mode  = \"binary\", shuffle = False)\n",
        "\n",
        "# Atributo do generator que fornece o número de amostras detectadas\n",
        "test_samples = test_generator.samples\n",
        "\n",
        "test_loss, test_acc = model.evaluate( test_generator )\n",
        "\n",
        "print(\"Test Accuracy:\", 100*test_acc, \"%\")\n",
        "print(\"Acertos: {} - Erros: {}\".format(round(test_samples * test_acc), \n",
        "                                       round(test_samples * (1-test_acc) )))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erZxBzNu8Q02"
      },
      "source": [
        "**a. Por que o ajuste fino é realizado do final para o começo (i.e. começando pelas últimas camadase indo em direção às primeiras)? Justifique.**\n",
        "\n",
        "<font color='green'>\n",
        "Pois a ultimas camadas são as mais relevantes para ajuste do modelo, normalmente contendo uma quantidade de parâmetros supeiror as camadas que estão no topo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HLEQw6S8Q03"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOOEM1_J8Q03"
      },
      "source": [
        "**b. Experimente descongelar mais camadas da VGG16 e continuar o ajuste fino. O que aconteceu?**\n",
        "<font color='green'>\n",
        "Ao descongelar mais algumas camadas do VGG16 percebe-se que os pesos que antes estavam congelados começam a variar conforme as epocas de treino vão avançando. Assim, também progredindo a performace do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_my824-c8Q03"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB6zj50m8Q04"
      },
      "source": [
        "### 4.2. Visualização dos Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kASqdDtD8Q04"
      },
      "source": [
        "def show_results(paths, ytest, ypred, labels, num = 25, tipo = \"rand\"):\n",
        "    \n",
        "    if tipo == \"acertos\":\n",
        "        fltr_idx = [i for i in range(ytest.shape[0]) if ypred[i] == ytest[i]]\n",
        "    else:\n",
        "        fltr_idx = [i for i in range(ytest.shape[0]) if ypred[i] != ytest[i]]\n",
        "        \n",
        "    indices = np.random.choice(fltr_idx, min(num, len(fltr_idx)), replace=False)\n",
        "       \n",
        "    rows = int(num/5)\n",
        "    fig, axs = plt.subplots(nrows = rows, ncols = 5, figsize=(20, 5*rows))\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        path = os.path.join(\".\", \"data\", \"test\", paths[idx])\n",
        "        img = cv2.imread(path)[:,:,::-1]\n",
        "        if ypred[idx] == ytest[idx]:\n",
        "            axs[i//5][i%5].set_title(labels[ytest[idx]], color = \"green\", fontsize = 20)\n",
        "        else:\n",
        "            axs[i//5][i%5].set_title(\"Pred: {}\\n Gabarito: {}\".format(labels[ypred[idx]], \n",
        "                                                                      labels[ytest[idx]]), color = \"red\", fontsize = 20)\n",
        "        \n",
        "        axs[i//5][i%5].imshow(img, vmin=0, vmax=255, cmap = \"gray\")\n",
        "    return\n",
        "\n",
        "test_generator.reset()\n",
        "filenames = test_generator.filenames\n",
        "labels = test_generator.labels\n",
        "\n",
        "pred_labels = model.predict(test_generator, verbose=0)\n",
        "preds = [int(pred[0] > 0.5) for pred in pred_labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOkbiSSH8Q04"
      },
      "source": [
        "#### Acertos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHkXP_GG8Q04"
      },
      "source": [
        "show_results(filenames, labels, preds, idx_to_class_dict, tipo = \"acertos\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQZ5MHmV8Q05"
      },
      "source": [
        "#### Erros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCAZf8vp8Q05"
      },
      "source": [
        "show_results(filenames, labels, preds, idx_to_class_dict, tipo = \"erros\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}